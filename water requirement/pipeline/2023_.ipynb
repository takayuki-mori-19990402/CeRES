{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "832a0b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230104_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230109_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230114_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230119_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230124_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230218_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230305_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230310_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230320_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230325_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230404_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230409_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230419_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230424_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230429_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230504_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230509_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230514_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230519_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230524_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230529_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230603_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230613_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230618_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230623_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230628_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230708_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230713_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230718_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230723_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230728_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230807_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230812_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230817_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230822_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230827_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230901_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230906_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230911_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230916_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230921_parcel.csv\n",
      "C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\20230926_parcel.csv\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m output_colums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m138025\u001b[39m))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_file \u001b[38;5;129;01min\u001b[39;00m sorted_files:\n\u001b[1;32m---> 50\u001b[0m     input_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8-sig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m138024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     input_list \u001b[38;5;241m=\u001b[39m input_df\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     52\u001b[0m     output_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(input_list))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:826\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "import glob\n",
    "from importlib import reload\n",
    "import natsort \n",
    "reload(natsort)\n",
    "from natsort import natsorted\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as ss\n",
    "\n",
    "# read 5day step csv file \n",
    "csv_path = glob.glob(r\"C:\\Users\\HONGO-23\\Desktop\\data\\01_Sentinel-2\\Cihea\\parcel\\2023\\*.csv\")\n",
    "#csv_path = glob.glob(r\"/Users/moritakayuki/Desktop/2022/*.csv\")\n",
    "sorted_files = natsorted(csv_path)\n",
    "for temp in sorted_files:\n",
    "    print(temp)\n",
    "    \n",
    "#欠損日を含む2023年のSentinel-2データ取得日\n",
    "year =['2023/']\n",
    "day_2022= ['1/4' ,'1/9','1/14','1/19','1/24','1/29','2/3','2/8','2/13','2/18','2/23','2/28','3/5',\n",
    "           '3/10','3/15','3/20','3/25','3/30','4/4','4/9','4/14','4/19','4/24','4/29','5/4',\n",
    "           '5/9','5/14','5/19','5/24','5/29','6/3','6/8','6/13','6/18','6/23','6/28','7/3',\n",
    "           '7/8','7/13','7/18','7/23','7/28','8/2','8/7','8/12','8/17','8/22','8/27','9/1',\n",
    "           '9/6','9/11','9/16','9/21','9/26']\n",
    "ymd_date_2023 = [year[0] + d for d in day_2022]\n",
    "\n",
    "#2023年のSentinel-2データ取得日\n",
    "year =['2023/']\n",
    "day= ['1/4','1/9','1/14','1/19','1/24','2/18','3/5','3/10','3/20','3/25','4/4','4/9',\n",
    "      '4/19','4/24','4/29','5/4','5/9','5/14','5/19','5/24','5/29','6/3','6/8',\n",
    "      '6/18','6/23','6/28','7/8','7/13','7/18','7/23','7/28','8/7','8/12','8/17',\n",
    "      '8/22','8/27','9/1','9/6','9/11','9/16','9/21','9/26'] \n",
    "ymd_date = [year[0] + d for d in day]\n",
    "\n",
    "# 対象期間の絞り込み（テストサイトの移植日は早くても-）\n",
    "year =['2023/']\n",
    "DOI= ['3/20','3/25','3/30','4/4','4/9','4/14',\n",
    "      '4/19','4/24','4/29','5/4','5/9','5/14','5/19','5/24','5/29','6/3','6/8','6/13',\n",
    "      '6/18','6/23','6/28','7/8','7/13','7/18','7/23','7/28','8/7','8/12','8/17',\n",
    "      '8/22','8/27','9/1','9/6','9/11','9/16','9/26'] \n",
    "doi_date_2023 = [year[0] + d for d in DOI]\n",
    "\n",
    "# read index \n",
    "output_list = []\n",
    "output_colums = list(range(1, 138025))\n",
    "for input_file in sorted_files:\n",
    "    input_df = pd.read_csv(input_file, encoding=\"utf-8-sig\", skiprows=1, nrows=138024, usecols=[21], header=None)\n",
    "    input_list = input_df.to_numpy().tolist()\n",
    "    output_row = list(itertools.chain.from_iterable(input_list))\n",
    "    output_list.append(output_row)\n",
    "\n",
    "# NDVI timeseries dataframe\n",
    "output_df = pd.DataFrame(output_list, columns=output_colums, index=ymd_date, dtype=np.float64)\n",
    "output_df_trans = output_df.T\n",
    "#output_df_trans.head()\n",
    "\n",
    "# Reindex to include NaN for missing dates in 2023\n",
    "output_df_2023 = output_df.reindex(index=ymd_date_2023)\n",
    "output_df_2023.replace(\"           nan\", np.nan, inplace=True)\n",
    "output_df_2023_t = output_df_2023.T\n",
    "\n",
    "# save\n",
    "output_df_2023.to_csv(r\"C:\\Users\\HONGO-23\\Desktop\\data\\ndvi_max day\\csv\\2023\\2023_timeseries_all.csv\")\n",
    "output_df_2023_t.to_csv(r\"C:\\Users\\HONGO-23\\Desktop\\data\\ndvi_max day\\csv\\2023\\2023_timeseries_all_t.csv\")\n",
    "\n",
    "# 対象期間の絞り込み\n",
    "doy_2023 = output_df_2023_t[doi_date_2023]\n",
    "doy_2023_t = doy_2023.T\n",
    "\n",
    "# save\n",
    "doy_2023_t.to_csv(r\"C:\\Users\\HONGO-23\\Desktop\\data\\ndvi_max day\\csv\\2023\\2023_timeseries_doi.csv\")\n",
    "doy_2023.to_csv(r\"C:\\Users\\HONGO-23\\Desktop\\data\\ndvi_max day\\csv\\2023\\2023_timeseries_doi_t.csv\")\n",
    "\n",
    "# Savitzy Golay filter\n",
    "a_int = doy_2023_testsite.interpolate()\n",
    "a_int.replace(np.nan, \"NaN\")\n",
    "b = a_int.dropna(axis=1)\n",
    "df_sg = pd.DataFrame(index=b.index)\n",
    "window_length = 13  \n",
    "polyorder = 4\n",
    "filtered = {}\n",
    "columns = list(b.columns)\n",
    "for i in range(124900):  \n",
    "    df_sg[columns[i]] = ss.savgol_filter(b[columns[i]], window_length=window_length, polyorder=polyorder)\n",
    "\n",
    "df_sg.to_csv(r\"C:\\Users\\HONGO-23\\Desktop\\data\\ndvi_max day\\csv\\2023\\2023_timeseries_sg_t.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2023/3/20-9/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDVI 最大日\n",
    "columns = list(df_sg.columns)\n",
    "max_index = df_sg.idxmax()\n",
    "df = pd.DataFrame(max_index,columns=['Max_Date'])\n",
    "df.index.name = 'OBJECTID'\n",
    "#df.to_csv(\"/Users/moritakayuki/Desktop/jupyter_notebook/NDVI.csv\")\n",
    "#df.to_csv(r\"C:\\Users\\HONGO-23\\Desktop\\test\\ndvi_max_date_2023.csv\")\n",
    "\n",
    "# 日付型に変換\n",
    "df['Max_Date'] = pd.to_datetime(df['Max_Date'])\n",
    "\n",
    "# 2023/2/23から2022/10/11までの日付を範囲としてカウント\n",
    "date_range = pd.date_range(start='2023/3/20', end='2023/9/26', freq='D')\n",
    "counts = df['Max_Date'].value_counts().reindex(date_range, fill_value=0)\n",
    "\n",
    "# カウントがある日付のみを取得\n",
    "valid_dates = counts[counts > 0]\n",
    "\n",
    "# 月日の形式に変換\n",
    "valid_dates.index = valid_dates.index.strftime('%m-%d')\n",
    "\n",
    "# 棒グラフをプロット\n",
    "plt.figure(figsize=(10, 6))\n",
    "valid_dates.plot(kind='bar')\n",
    "plt.title('Count of heading Date')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2120d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max_Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJECTID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132109</th>\n",
       "      <td>2023-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132110</th>\n",
       "      <td>2023-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132111</th>\n",
       "      <td>2023-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132112</th>\n",
       "      <td>2023-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132113</th>\n",
       "      <td>2023-04-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Max_Date\n",
       "OBJECTID           \n",
       "1        2023-07-18\n",
       "2        2023-07-18\n",
       "3        2023-07-18\n",
       "4        2023-07-18\n",
       "5        2023-07-18\n",
       "...             ...\n",
       "132109   2023-04-24\n",
       "132110   2023-04-24\n",
       "132111   2023-04-19\n",
       "132112   2023-04-24\n",
       "132113   2023-04-24\n",
       "\n",
       "[124900 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa5727ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#出穂日からの経過日数算出準備\n",
    "import csv\n",
    "\n",
    "# DOI日付リスト\n",
    "year = ['2023/']\n",
    "DOI = ['3/20','3/25','4/4','4/9','4/19','4/24','4/29','5/4','5/9','5/14','5/19','5/24',\n",
    "       '5/29','6/3','6/8','6/18','6/23','6/28','7/8','7/13','7/18','7/23','7/28','8/7',\n",
    "       '8/12','8/17','8/22','8/27','9/1','9/6','9/11','9/16','9/21','9/26'] \n",
    "doi_date_2023 = [year[0] + d for d in DOI]\n",
    "\n",
    "# 既存のCSVファイルを読み込む\n",
    "input_file_path = r\"C:\\Users\\HONGO-23\\Desktop\\test\\ndvi_max_date_2023.csv\"\n",
    "output_file_path = r\"C:\\Users\\HONGO-23\\Desktop\\test\\ndvi_max_date_2023_updated.csv\"\n",
    "\n",
    "with open(input_file_path, 'r', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    data = list(reader)\n",
    "\n",
    "# ヘッダーリストを作成し、初期化\n",
    "min_length = max(len(data[0]), len(doi_date_2023) + 2)\n",
    "header = [\"\"] * min_length\n",
    "\n",
    "# 0列目と1列目にヘッダーを書き込む\n",
    "header[0] = \"OBJECTID\"\n",
    "header[1] = \"max date\"\n",
    "\n",
    "# 2列飛ばしてヘッダーを書き込む\n",
    "for i, value in enumerate(doi_date_2023):\n",
    "    header[i + 2] = value\n",
    "\n",
    "# ヘッダーをデータに反映\n",
    "data[0] = header\n",
    "\n",
    "# 修正したデータを新しいCSVファイルに書き込む\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(data)\n",
    "\n",
    "#OBJECT ID&ndvi max dateは手動で書き込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40ac793e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>max date</th>\n",
       "      <th>2023/3/20</th>\n",
       "      <th>2023/3/25</th>\n",
       "      <th>2023/4/4</th>\n",
       "      <th>2023/4/9</th>\n",
       "      <th>2023/4/19</th>\n",
       "      <th>2023/4/24</th>\n",
       "      <th>2023/4/29</th>\n",
       "      <th>2023/5/4</th>\n",
       "      <th>...</th>\n",
       "      <th>2023/8/12</th>\n",
       "      <th>2023/8/17</th>\n",
       "      <th>2023/8/22</th>\n",
       "      <th>2023/8/27</th>\n",
       "      <th>2023/9/1</th>\n",
       "      <th>2023/9/6</th>\n",
       "      <th>2023/9/11</th>\n",
       "      <th>2023/9/16</th>\n",
       "      <th>2023/9/21</th>\n",
       "      <th>2023/9/26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023/7/18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023/7/18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2023/7/18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023/7/18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023/7/18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID   max date  2023/3/20  2023/3/25  2023/4/4  2023/4/9  2023/4/19  \\\n",
       "0         1  2023/7/18        NaN        NaN       NaN       NaN        NaN   \n",
       "1         2  2023/7/18        NaN        NaN       NaN       NaN        NaN   \n",
       "2         3  2023/7/18        NaN        NaN       NaN       NaN        NaN   \n",
       "3         4  2023/7/18        NaN        NaN       NaN       NaN        NaN   \n",
       "4         5  2023/7/18        NaN        NaN       NaN       NaN        NaN   \n",
       "\n",
       "   2023/4/24  2023/4/29  2023/5/4  ...  2023/8/12  2023/8/17  2023/8/22  \\\n",
       "0        NaN        NaN       NaN  ...        NaN        NaN        NaN   \n",
       "1        NaN        NaN       NaN  ...        NaN        NaN        NaN   \n",
       "2        NaN        NaN       NaN  ...        NaN        NaN        NaN   \n",
       "3        NaN        NaN       NaN  ...        NaN        NaN        NaN   \n",
       "4        NaN        NaN       NaN  ...        NaN        NaN        NaN   \n",
       "\n",
       "   2023/8/27  2023/9/1  2023/9/6  2023/9/11  2023/9/16  2023/9/21  2023/9/26  \n",
       "0        NaN       NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "1        NaN       NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "2        NaN       NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "3        NaN       NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "4        NaN       NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\HONGO-23\\Desktop\\test\\ndvi_max_date_2023_updated.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7addb9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ファイルパス\n",
    "file_path = r\"C:\\Users\\HONGO-23\\Desktop\\test\\ndvi_max_date_2023_updated.csv\"\n",
    "\n",
    "# CSVファイルを読み込み\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1列目1行目の日付を基準日として取得\n",
    "base_date = pd.to_datetime(df.iloc[0, 1])\n",
    "\n",
    "# 0行2列目から右側の日付を取得し、基準日との差を計算\n",
    "for col in range(2, df.shape[1]):\n",
    "    current_date = pd.to_datetime(df.iloc[0, col])\n",
    "    days_difference = (current_date - base_date).days\n",
    "    df.iloc[1:, col] = days_difference\n",
    "\n",
    "# 結果を書き込む\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf503a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
